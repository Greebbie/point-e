{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510ca893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from point_e.diffusion.sampler import PointCloudSampler\n",
    "from point_e.diffusion.configs import DIFFUSION_CONFIGS\n",
    "from point_e.models.configs import MODEL_CONFIGS, model_from_config\n",
    "from point_e.models.download import load_checkpoint\n",
    "from point_e.models.multimodal import MultimodalPointDiffusionTransformer\n",
    "from point_e.util.plotting import plot_point_cloud\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "# CLIP preprocessing transform\n",
    "def get_clip_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(224, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.48145466, 0.4578275, 0.40821073), \n",
    "                             (0.26862954, 0.26130258, 0.27577711))\n",
    "    ])\n",
    "\n",
    "def main():\n",
    "    # Setup device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Create the base multimodal model\n",
    "    model_config = MODEL_CONFIGS['base40M'].copy()\n",
    "    base_model = MultimodalPointDiffusionTransformer(\n",
    "        device=device,\n",
    "        **model_config\n",
    "    )\n",
    "    base_diffusion = diffusion_from_config(DIFFUSION_CONFIGS['base40M'])\n",
    "    \n",
    "    # Create the upsampler model (original Point-E)\n",
    "    upsampler_model = model_from_config(MODEL_CONFIGS['upsample'], device)\n",
    "    upsampler_diffusion = diffusion_from_config(DIFFUSION_CONFIGS['upsample'])\n",
    "    \n",
    "    # Load checkpoints\n",
    "    base_model.load_state_dict(torch.load(\"multimodal_point_e_final.pt\", map_location=device))\n",
    "    upsampler_model.load_state_dict(load_checkpoint('upsample', device))\n",
    "    \n",
    "    # Set models to eval mode\n",
    "    base_model.eval()\n",
    "    upsampler_model.eval()\n",
    "    \n",
    "    # Create sampler\n",
    "    sampler = PointCloudSampler(\n",
    "        device=device,\n",
    "        models=[base_model, upsampler_model],\n",
    "        diffusions=[base_diffusion, upsampler_diffusion],\n",
    "        num_points=[1024, 4096 - 1024],\n",
    "        aux_channels=['R', 'G', 'B'],\n",
    "        guidance_scale=[3.0, 3.0],\n",
    "    )\n",
    "    \n",
    "    # Prepare inputs\n",
    "    transform = get_clip_transform()\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    image_path = \"example_image.jpg\"\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Text prompt\n",
    "    text_prompt = \"a red motorcycle with chrome details\"\n",
    "    \n",
    "    # Generate point cloud\n",
    "    print(\"Generating point cloud...\")\n",
    "    samples = None\n",
    "    with torch.no_grad():\n",
    "        for x in tqdm(sampler.sample_batch_progressive(\n",
    "            batch_size=1, \n",
    "            model_kwargs=dict(images=image, texts=[text_prompt])\n",
    "        )):\n",
    "            samples = x\n",
    "    \n",
    "    # Convert to point cloud\n",
    "    pc = sampler.output_to_point_clouds(samples)[0]\n",
    "    \n",
    "    # Visualize\n",
    "    fig = plot_point_cloud(pc, grid_size=1)\n",
    "    fig.savefig(\"multimodal_output.png\")\n",
    "    \n",
    "    # Save point cloud\n",
    "    pc.save(\"multimodal_output.npz\")\n",
    "    \n",
    "    print(f\"Generated point cloud saved to multimodal_output.npz\")\n",
    "    print(f\"Visualization saved to multimodal_output.png\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
