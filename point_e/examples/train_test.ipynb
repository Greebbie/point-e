{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "510ca893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from point_e.models.fusion import TextImageFusionModule\n",
    "from point_e.models.multimodal import SimpleMultimodalTransformer\n",
    "from point_e.models.configs import MODEL_CONFIGS\n",
    "from point_e.models.download import load_checkpoint\n",
    "\n",
    "from point_e.diffusion.sampler import PointCloudSampler\n",
    "from point_e.diffusion.configs import DIFFUSION_CONFIGS\n",
    "from point_e.models.configs import MODEL_CONFIGS, model_from_config\n",
    "from point_e.models.download import load_checkpoint\n",
    "from point_e.util.plotting import plot_point_cloud\n",
    "\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c607b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing TextImageFusionModule...\n",
      "Input shapes: text_emb torch.Size([2, 768]), img_tokens torch.Size([2, 196, 768])\n",
      "Output shape: torch.Size([2, 512])\n",
      "Fusion module test passed!\n"
     ]
    }
   ],
   "source": [
    "# 测试融合模块\n",
    "def test_fusion_module():\n",
    "    print(\"Testing TextImageFusionModule...\")\n",
    "    fusion = TextImageFusionModule(text_dim=768, image_dim=768,fusion_dim=512)\n",
    "    \n",
    "    # 创建随机输入\n",
    "    batch_size = 2\n",
    "    text_emb = torch.randn(batch_size, 768)\n",
    "    img_tokens = torch.randn(batch_size, 196, 768)  # 196 = 14x14 grid\n",
    "    \n",
    "    # 前向传递\n",
    "    out = fusion(text_emb, img_tokens)\n",
    "    \n",
    "    \n",
    "    print(f\"Input shapes: text_emb {text_emb.shape}, img_tokens {img_tokens.shape}\")\n",
    "    print(f\"Output shape: {out.shape}\")\n",
    "    print(\"Fusion module test passed!\")\n",
    "if __name__ == \"__main__\":\n",
    "    test_fusion_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "904565ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SimpleMultimodalTransformer…\n",
      "✔ Model initialized.\n",
      "Running forward pass…\n",
      "→ out.shape = torch.Size([2, 12, 1024])\n",
      "✔ Forward pass successful!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from point_e.models.multimodal import SimpleMultimodalTransformer\n",
    "\n",
    "def test_simple_multimodal_transformer():\n",
    "    print(\"Testing SimpleMultimodalTransformer…\")\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "    # 1) 实例化\n",
    "    model = SimpleMultimodalTransformer(device=device, dtype=torch.float32)\n",
    "    model.eval()\n",
    "    print(\"✔ Model initialized.\")\n",
    "\n",
    "    # 2) 拿到期望的输入维度\n",
    "    B     = 2\n",
    "    C_in  = model.input_channels  # 默认 6\n",
    "    T_ctx = model.n_ctx          # 1024（或加上 grid tokens，取决于你初始化时的写法）\n",
    "    \n",
    "    # 3) 随机造 x, t\n",
    "    x = torch.randn(B, C_in, T_ctx)\n",
    "    t = torch.randint(0, 1000, (B,), dtype=torch.long)\n",
    "    \n",
    "    # 4) 造一批 PIL Image\n",
    "    dummy_imgs = [\n",
    "        Image.fromarray((np.random.rand(224,224,3)*255).astype(np.uint8))\n",
    "        for _ in range(B)\n",
    "    ]\n",
    "    dummy_texts = [\"a red chair\", \"a blue table\"]\n",
    "\n",
    "    # 5) forward\n",
    "    print(\"Running forward pass…\")\n",
    "    out = model(x, t, images=dummy_imgs, texts=dummy_texts)\n",
    "    print(f\"→ out.shape = {out.shape}\")\n",
    "\n",
    "    # 6) 简单断言\n",
    "    assert isinstance(out, torch.Tensor), \"输出必须是 Tensor\"\n",
    "    assert out.shape[0] == B, f\"第一维（batch）应为 {B}\"\n",
    "    print(\"✔ Forward pass successful!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_simple_multimodal_transformer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6289d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing training loop…\n",
      "Training loss: 1.0100\n",
      "Training loop test passed!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from point_e.models.multimodal import SimpleMultimodalTransformer\n",
    "from point_e.diffusion.configs import DIFFUSION_CONFIGS, diffusion_from_config\n",
    "\n",
    "def test_training_loop():\n",
    "    print(\"Testing training loop…\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "    # 1) 实例化模型 & diffusion\n",
    "    model = SimpleMultimodalTransformer(device=device, dtype=torch.float32)\n",
    "    diffusion = diffusion_from_config(DIFFUSION_CONFIGS['base40M'])\n",
    "    model.train()\n",
    "\n",
    "    # 2) 冻结 backbone，解冻 fusion & CLIP embed\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(\"fusion\") or name.startswith(\"clip.model\"):\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False\n",
    "\n",
    "    optimizer = optim.AdamW(\n",
    "        [p for p in model.parameters() if p.requires_grad],\n",
    "        lr=1e-4,\n",
    "    )\n",
    "\n",
    "    # 3) 构造 dummy batch\n",
    "    B = 2\n",
    "    # point_clouds: [B, C_in, T_ctx]\n",
    "    pc = torch.randn(B, model.input_channels, model.n_ctx, device=device)\n",
    "\n",
    "    # images: list of PIL Image\n",
    "    imgs = [\n",
    "        Image.fromarray((np.random.rand(224,224,3)*255).astype(np.uint8))\n",
    "        for _ in range(B)\n",
    "    ]\n",
    "    texts = [\"a red chair\", \"a blue table\"]\n",
    "\n",
    "    # 4) 训练一步\n",
    "    t = torch.randint(0, diffusion.num_timesteps, (B,), device=device)\n",
    "    model_kwargs = {\"images\": imgs, \"texts\": texts}\n",
    "\n",
    "    try:\n",
    "        losses = diffusion.training_losses(\n",
    "            model=model,\n",
    "            x_start=pc,\n",
    "            t=t,\n",
    "            model_kwargs=model_kwargs\n",
    "        )\n",
    "        loss = losses[\"loss\"].mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Training loss: {loss.item():.4f}\")\n",
    "        print(\"Training loop test passed!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in training loop test: {e}\")\n",
    "        import traceback; traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_training_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "532b78cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "\n",
    "# from point_e.models.multimodal import SimpleMultimodalTransformer\n",
    "# from point_e.models.configs import MODEL_CONFIGS, model_from_config\n",
    "# from point_e.diffusion.configs import DIFFUSION_CONFIGS, diffusion_from_config\n",
    "# from point_e.diffusion.sampler import PointCloudSampler\n",
    "\n",
    "# def test_generation_two_stage():\n",
    "#     print(\"Testing two-stage point cloud generation…\")\n",
    "#     device = torch.device(\"cpu\")\n",
    "#     B = 1\n",
    "\n",
    "#     # ——— 1) Base Stage: 1024 pts ———\n",
    "#     base_model = SimpleMultimodalTransformer(device=device, dtype=torch.float32).eval()\n",
    "#     base_diff = diffusion_from_config(DIFFUSION_CONFIGS[\"base40M\"])\n",
    "#     base_sampler = PointCloudSampler(\n",
    "#         device=device,\n",
    "#         models=[base_model],\n",
    "#         diffusions=[base_diff],\n",
    "#         num_points=[1024],\n",
    "#         aux_channels=['R', 'G', 'B'],\n",
    "#         guidance_scale=[3.0],\n",
    "#         use_karras=[True],\n",
    "#         karras_steps=[2],\n",
    "#         sigma_min=[None],  # Fix: Ensure length matches n=1\n",
    "#         sigma_max=[None],\n",
    "#         s_churn=[0.0],\n",
    "#     )\n",
    "\n",
    "#     # Dummy image + prompt\n",
    "#     img = Image.fromarray((np.random.rand(224, 224, 3) * 255).astype(np.uint8))\n",
    "#     prompt = \"a red chair\"\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         low_res = base_sampler.sample_batch(\n",
    "#             batch_size=B,\n",
    "#             model_kwargs={'images': [img], 'texts': [prompt]},\n",
    "#         )\n",
    "#     print(\"✔ Base stage output:\", low_res.shape)\n",
    "#     assert low_res.shape[2] == 1024\n",
    "\n",
    "#     # ——— 2) Upsample Stage: 1024→4096 pts ———\n",
    "#     up_model = model_from_config(MODEL_CONFIGS[\"upsample\"], device=device).eval()\n",
    "#     up_diff = diffusion_from_config(DIFFUSION_CONFIGS[\"upsample\"])\n",
    "#     up_sampler = PointCloudSampler(\n",
    "#         device=device,\n",
    "#         models=[up_model],\n",
    "#         diffusions=[up_diff],\n",
    "#         num_points=[4096 - 1024],\n",
    "#         aux_channels=['R', 'G', 'B'],\n",
    "#         guidance_scale=[3.0],\n",
    "#         use_karras=[True],\n",
    "#         karras_steps=[2],\n",
    "#         sigma_min=[None],  # Fix: Ensure length matches n=1\n",
    "#         sigma_max=[None],\n",
    "#         s_churn=[0.0],\n",
    "#     )\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         high_res = up_sampler.sample_batch(\n",
    "#             batch_size=B,\n",
    "#             model_kwargs={'low_res': low_res},\n",
    "#         )\n",
    "#     print(\"✔ Upsample stage output:\", high_res.shape)\n",
    "#     assert high_res.shape[2] == 4096 - 1024\n",
    "\n",
    "#     # ——— 3) 拼接最终点云 ———\n",
    "#     final_pc = torch.cat([low_res, high_res], dim=2)\n",
    "#     assert final_pc.shape[2] == 4096\n",
    "#     print(\"✔ Two-stage generation successful, final shape:\", final_pc.shape)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     test_generation_two_stage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
